{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-24T09:11:23.420976Z","iopub.execute_input":"2022-11-24T09:11:23.421321Z","iopub.status.idle":"2022-11-24T09:11:23.528425Z","shell.execute_reply.started":"2022-11-24T09:11:23.421252Z","shell.execute_reply":"2022-11-24T09:11:23.527728Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/110-1-ntut-ee-ai-hw1/pred_results.csv\n/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n/kaggle/input/fashionmnist/fashion-mnist_test.csv\n/kaggle/input/fashionmnist/fashion-mnist_train.csv\n/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n/kaggle/input/fashionmnist/train-images-idx3-ubyte\n","output_type":"stream"}]},{"cell_type":"code","source":"# Read the Fashion MNIST data from local CSV file\n\ndf_train = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_test.csv\")\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:11:23.529886Z","iopub.execute_input":"2022-11-24T09:11:23.530214Z","iopub.status.idle":"2022-11-24T09:11:29.775887Z","shell.execute_reply.started":"2022-11-24T09:11:23.530165Z","shell.execute_reply":"2022-11-24T09:11:29.775087Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0      2       0       0       0       0       0       0       0       0   \n1      9       0       0       0       0       0       0       0       0   \n2      6       0       0       0       0       0       0       0       5   \n3      0       0       0       0       1       2       0       0       0   \n4      3       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0        30        43         0   \n3       0  ...         3         0         0         0         0         1   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel781  pixel782  pixel783  pixel784  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Get train images and labels from CSV file\n\ntrain_images = np.array(df_train.drop([\"label\"], axis=1))\ntrain_labels = np.array(df_train[\"label\"])\ntest_images = np.array(df_test.drop([\"label\"], axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:11:29.777266Z","iopub.execute_input":"2022-11-24T09:11:29.777506Z","iopub.status.idle":"2022-11-24T09:11:30.069196Z","shell.execute_reply.started":"2022-11-24T09:11:29.777474Z","shell.execute_reply":"2022-11-24T09:11:30.068477Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# We have 60,000 training samples, each vecotr has 784 pixels (28*28)\ntrain_images = train_images.reshape((60000, 28, 28, 1))\ntest_images = test_images.reshape((10000, 28, 28, 1))\ntest_images.shape\ntrain_images.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:11:30.070900Z","iopub.execute_input":"2022-11-24T09:11:30.071161Z","iopub.status.idle":"2022-11-24T09:11:30.077568Z","shell.execute_reply.started":"2022-11-24T09:11:30.071133Z","shell.execute_reply":"2022-11-24T09:11:30.076796Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(60000, 28, 28, 1)"},"metadata":{}}]},{"cell_type":"code","source":"# Display training data with pyplot. Remember to reshape the image vector\n\nimport matplotlib.pyplot as plt\nplt.imshow(np.reshape(train_images[0], (28,28)), cmap=plt.cm.binary)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:11:30.079025Z","iopub.execute_input":"2022-11-24T09:11:30.079555Z","iopub.status.idle":"2022-11-24T09:11:30.291501Z","shell.execute_reply.started":"2022-11-24T09:11:30.079521Z","shell.execute_reply":"2022-11-24T09:11:30.291013Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"from tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D,Activation,BatchNormalization\nnetwork = models.Sequential()\nnetwork.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(28 , 28,1)))\nnetwork.add(Activation(\"relu\"))\nnetwork.add(Conv2D(32, (3, 3), padding=\"same\"))\nnetwork.add(Activation(\"relu\"))\nnetwork.add(MaxPooling2D(pool_size=(2, 2)))\nnetwork.add(BatchNormalization())\nnetwork.add(Dropout(0.3))\nnetwork.add(Conv2D(64, (3, 3), padding=\"same\",input_shape=(28 , 28,1)))\nnetwork.add(Activation(\"relu\"))\nnetwork.add(Conv2D(64, (3, 3), padding=\"same\"))\nnetwork.add(Activation(\"relu\"))\nnetwork.add(MaxPooling2D(pool_size=(2, 2)))\nnetwork.add(BatchNormalization())\nnetwork.add(Dropout(0.3))\nnetwork.add(Conv2D(128, (3, 3), padding=\"same\"))\nnetwork.add(Activation(\"relu\"))\nnetwork.add(Conv2D(128, (3, 3), padding=\"same\"))\nnetwork.add(Activation(\"relu\"))\nnetwork.add(MaxPooling2D(pool_size=(2, 2)))\nnetwork.add(BatchNormalization())\nnetwork.add(Dropout(0.3))\nnetwork.add(Conv2D(256, (3, 3), padding=\"same\"))\nnetwork.add(Activation(\"relu\"))\nnetwork.add(Conv2D(256, (3, 3), padding=\"same\"))\nnetwork.add(Activation(\"relu\"))\nnetwork.add(MaxPooling2D(pool_size=(2, 2)))\nnetwork.add(BatchNormalization())\nnetwork.add(Dropout(0.4))\nnetwork.add(Flatten())\nnetwork.add(Dense(512))\nnetwork.add(BatchNormalization())\nnetwork.add(Dropout(0.5))\nnetwork.add(layers.Dense(10, activation='softmax'))\nnetwork.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:11:30.292722Z","iopub.execute_input":"2022-11-24T09:11:30.293173Z","iopub.status.idle":"2022-11-24T09:11:37.738637Z","shell.execute_reply.started":"2022-11-24T09:11:30.293140Z","shell.execute_reply":"2022-11-24T09:11:37.737915Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2022-11-24 09:11:30.962656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2022-11-24 09:11:35.421165: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-11-24 09:11:35.425028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2022-11-24 09:11:35.489810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-24 09:11:35.490521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2022-11-24 09:11:35.490571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2022-11-24 09:11:35.522238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2022-11-24 09:11:35.522312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2022-11-24 09:11:35.544756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2022-11-24 09:11:35.553607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2022-11-24 09:11:35.582014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2022-11-24 09:11:35.590363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2022-11-24 09:11:35.594170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2022-11-24 09:11:35.594359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-24 09:11:35.595098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-24 09:11:35.596634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2022-11-24 09:11:35.597626: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-24 09:11:35.597851: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-11-24 09:11:35.598017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-24 09:11:35.598668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2022-11-24 09:11:35.598718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2022-11-24 09:11:35.598752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2022-11-24 09:11:35.598773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2022-11-24 09:11:35.598789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2022-11-24 09:11:35.598803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2022-11-24 09:11:35.598818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2022-11-24 09:11:35.598835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2022-11-24 09:11:35.598850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2022-11-24 09:11:35.598930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-24 09:11:35.599605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-24 09:11:35.600213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2022-11-24 09:11:35.601337: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2022-11-24 09:11:37.177835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2022-11-24 09:11:37.177879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2022-11-24 09:11:37.177890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2022-11-24 09:11:37.180511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-24 09:11:37.181404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-24 09:11:37.182054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-24 09:11:37.182659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 28, 28, 32)        320       \n_________________________________________________________________\nactivation (Activation)      (None, 28, 28, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 28, 28, 32)        0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 14, 14, 32)        128       \n_________________________________________________________________\ndropout (Dropout)            (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 14, 14, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n_________________________________________________________________\nactivation_3 (Activation)    (None, 14, 14, 64)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 7, 7, 64)          256       \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 7, 7, 64)          0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 7, 7, 128)         73856     \n_________________________________________________________________\nactivation_4 (Activation)    (None, 7, 7, 128)         0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 7, 7, 128)         147584    \n_________________________________________________________________\nactivation_5 (Activation)    (None, 7, 7, 128)         0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 3, 3, 128)         512       \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 3, 3, 128)         0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 3, 3, 256)         295168    \n_________________________________________________________________\nactivation_6 (Activation)    (None, 3, 3, 256)         0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 3, 3, 256)         590080    \n_________________________________________________________________\nactivation_7 (Activation)    (None, 3, 3, 256)         0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 1, 1, 256)         1024      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 1, 1, 256)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 256)               0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               131584    \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 512)               2048      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 1,312,362\nTrainable params: 1,310,378\nNon-trainable params: 1,984\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"network.compile(optimizer='rmsprop',\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:11:37.739793Z","iopub.execute_input":"2022-11-24T09:11:37.740094Z","iopub.status.idle":"2022-11-24T09:11:37.756361Z","shell.execute_reply.started":"2022-11-24T09:11:37.740060Z","shell.execute_reply":"2022-11-24T09:11:37.755376Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Normalize the training images\ntrn_images = train_images.astype('float32') / 255\ntst_images = test_images.astype('float32') / 255","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:11:37.759021Z","iopub.execute_input":"2022-11-24T09:11:37.759239Z","iopub.status.idle":"2022-11-24T09:11:37.879129Z","shell.execute_reply.started":"2022-11-24T09:11:37.759212Z","shell.execute_reply":"2022-11-24T09:11:37.878344Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ntrn_labels = to_categorical(train_labels)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:11:37.880470Z","iopub.execute_input":"2022-11-24T09:11:37.880946Z","iopub.status.idle":"2022-11-24T09:11:37.889078Z","shell.execute_reply.started":"2022-11-24T09:11:37.880907Z","shell.execute_reply":"2022-11-24T09:11:37.888353Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"network.fit(trn_images, trn_labels, epochs=70, batch_size=128)\n#60  128 has best \n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:11:37.891856Z","iopub.execute_input":"2022-11-24T09:11:37.892139Z","iopub.status.idle":"2022-11-24T09:17:39.083122Z","shell.execute_reply.started":"2022-11-24T09:11:37.892085Z","shell.execute_reply":"2022-11-24T09:17:39.082365Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2022-11-24 09:11:38.205602: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2022-11-24 09:11:38.217572: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000179999 Hz\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/70\n","output_type":"stream"},{"name":"stderr","text":"2022-11-24 09:11:39.989929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2022-11-24 09:11:41.005324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2022-11-24 09:11:41.034535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","output_type":"stream"},{"name":"stdout","text":"469/469 [==============================] - 14s 11ms/step - loss: 0.8956 - accuracy: 0.7124\nEpoch 2/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.3551 - accuracy: 0.8756\nEpoch 3/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.2828 - accuracy: 0.8972\nEpoch 4/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.2506 - accuracy: 0.9089\nEpoch 5/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.2299 - accuracy: 0.9185\nEpoch 6/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.2183 - accuracy: 0.9227\nEpoch 7/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.2034 - accuracy: 0.9281\nEpoch 8/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1888 - accuracy: 0.9323\nEpoch 9/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1860 - accuracy: 0.9330\nEpoch 10/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1766 - accuracy: 0.9370\nEpoch 11/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1625 - accuracy: 0.9418\nEpoch 12/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1607 - accuracy: 0.9421\nEpoch 13/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1514 - accuracy: 0.9450\nEpoch 14/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1428 - accuracy: 0.9493\nEpoch 15/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1401 - accuracy: 0.9502\nEpoch 16/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1363 - accuracy: 0.9506\nEpoch 17/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1299 - accuracy: 0.9530\nEpoch 18/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1283 - accuracy: 0.9530\nEpoch 19/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1240 - accuracy: 0.9560\nEpoch 20/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1200 - accuracy: 0.9576\nEpoch 21/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1149 - accuracy: 0.9572\nEpoch 22/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1114 - accuracy: 0.9600\nEpoch 23/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1079 - accuracy: 0.9614\nEpoch 24/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.1044 - accuracy: 0.9629\nEpoch 25/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0979 - accuracy: 0.9656\nEpoch 26/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0996 - accuracy: 0.9643\nEpoch 27/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0985 - accuracy: 0.9650\nEpoch 28/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0917 - accuracy: 0.9671\nEpoch 29/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0907 - accuracy: 0.9680\nEpoch 30/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0840 - accuracy: 0.9700\nEpoch 31/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0903 - accuracy: 0.9669\nEpoch 32/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0850 - accuracy: 0.9708\nEpoch 33/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0846 - accuracy: 0.9707\nEpoch 34/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0830 - accuracy: 0.9715\nEpoch 35/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0806 - accuracy: 0.9716\nEpoch 36/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0750 - accuracy: 0.9731\nEpoch 37/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0734 - accuracy: 0.9743\nEpoch 38/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0734 - accuracy: 0.9740\nEpoch 39/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0741 - accuracy: 0.9737\nEpoch 40/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0702 - accuracy: 0.9756\nEpoch 41/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0686 - accuracy: 0.9754\nEpoch 42/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0687 - accuracy: 0.9755\nEpoch 43/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0675 - accuracy: 0.9762\nEpoch 44/70\n469/469 [==============================] - 5s 10ms/step - loss: 0.0644 - accuracy: 0.9781\nEpoch 45/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0642 - accuracy: 0.9776\nEpoch 46/70\n469/469 [==============================] - 5s 10ms/step - loss: 0.0597 - accuracy: 0.9796\nEpoch 47/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0657 - accuracy: 0.9771\nEpoch 48/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0575 - accuracy: 0.9797\nEpoch 49/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0600 - accuracy: 0.9780\nEpoch 50/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0613 - accuracy: 0.9781\nEpoch 51/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0591 - accuracy: 0.9796\nEpoch 52/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0559 - accuracy: 0.9805\nEpoch 53/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0558 - accuracy: 0.9802\nEpoch 54/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0588 - accuracy: 0.9792\nEpoch 55/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0537 - accuracy: 0.9810\nEpoch 56/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0527 - accuracy: 0.9820\nEpoch 57/70\n469/469 [==============================] - 5s 10ms/step - loss: 0.0525 - accuracy: 0.9820\nEpoch 58/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0540 - accuracy: 0.9814\nEpoch 59/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0496 - accuracy: 0.9828\nEpoch 60/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0504 - accuracy: 0.9820\nEpoch 61/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0530 - accuracy: 0.9815\nEpoch 62/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0484 - accuracy: 0.9825\nEpoch 63/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0474 - accuracy: 0.9834\nEpoch 64/70\n469/469 [==============================] - 5s 10ms/step - loss: 0.0518 - accuracy: 0.9827\nEpoch 65/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0485 - accuracy: 0.9834\nEpoch 66/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0482 - accuracy: 0.9840\nEpoch 67/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0455 - accuracy: 0.9850\nEpoch 68/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0470 - accuracy: 0.9845\nEpoch 69/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0465 - accuracy: 0.9838\nEpoch 70/70\n469/469 [==============================] - 5s 11ms/step - loss: 0.0461 - accuracy: 0.9839\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f750407f650>"},"metadata":{}}]},{"cell_type":"code","source":"# Prdict the class of each test image\n#results = network.predict_classes(tst_images)\nresults = np.argmax(network.predict(tst_images), axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:17:39.085059Z","iopub.execute_input":"2022-11-24T09:17:39.085347Z","iopub.status.idle":"2022-11-24T09:17:39.934365Z","shell.execute_reply.started":"2022-11-24T09:17:39.085309Z","shell.execute_reply":"2022-11-24T09:17:39.933600Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Print results in CSV format for uploading to Kaggle\nwith open('pred_results.csv', 'w') as f:\n    f.write('Id,Category\\n')\n    for i in range(len(results)):\n        f.write(str(i) + ',' + str(results[i]) + '\\n')","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:17:39.935890Z","iopub.execute_input":"2022-11-24T09:17:39.936216Z","iopub.status.idle":"2022-11-24T09:17:39.955543Z","shell.execute_reply.started":"2022-11-24T09:17:39.936165Z","shell.execute_reply":"2022-11-24T09:17:39.954922Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Upload your results to Kaggle\nfrom IPython.display import FileLink\nFileLink('pred_results.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-24T09:17:39.956939Z","iopub.execute_input":"2022-11-24T09:17:39.957226Z","iopub.status.idle":"2022-11-24T09:17:39.963232Z","shell.execute_reply.started":"2022-11-24T09:17:39.957174Z","shell.execute_reply":"2022-11-24T09:17:39.962385Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/pred_results.csv","text/html":"<a href='pred_results.csv' target='_blank'>pred_results.csv</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}